<?xml version="1.0"?>
<TeamMentor_Article Metadata_Hash="1063426137" Content_Hash="1832299997">
  <Metadata>
    <Id>8c2075f4-5334-4fcc-9cff-17b06cf2e1d2</Id>
    <Id_History>a5428c5d-a063-48b0-85f1-27468c71e01a,</Id_History>
    <Library_Id>c4b9cb6a-4561-4451-9b6c-4e59d73584f6</Library_Id>
    <Title>Audit And Log Access Across Application Tiers</Title>
    <Category>Auditing and Logging</Category>
    <Phase>Design</Phase>
    <Technology>Web Application</Technology>
    <Type>Guideline</Type>
    <DirectLink>Audit And Log Access Across Application Tiers</DirectLink>
    <Tag />
    <Security_Demand />
    <Author />
    <Priority>J.D. Meier, Alex Mackman, Michael Dunner, Srinath Vasireddy, Ray Escamilla and Anandha Murukan</Priority>
    <Status />
    <Source>SI</Source>
  </Metadata>
  <Content Sanitized="true" DataType="Html">
    <Data><![CDATA[<h1>Applies to</h1>
  <ul>
    <li>Web Application</li>
  </ul>
  <h1>What to Do</h1>
  <p>Audit and log access across the tiers of your application for tracking, verification, and non-repudiation.&amp;nbsp; Use a combination of application-level logging and platform auditing features.</p>
  <h1>Why</h1>
  <p>Auditing at only a single level opens your system to attacks on other layers which avoid your logging system entirely.&amp;nbsp; Also, systems which do not allow for the correlation of log files open themselves to attacks which seem innocuous at each layer, but are in fact harmful when looked at on the larger level.</p>
  <span>
  </span>
  <h1>When</h1>
  <p>All systems with multiple tiers (even just web and database) should log at each level.&amp;nbsp; If the system is complex enough or receives enough traffic that cross-tier tracking can't be done trivially by hand, they should provide ways to merge the log files into a business-activity view.</p>
  <span>
  </span>
  <h1>How</h1>
  <p>The goal for integrated logging is to provide certain guarantees for activities within the system, as well as monitoring basic system functionality.&amp;nbsp; Logs at each tier can provide sufficient information about system activity, but they do less well at providing a useful viewpoint on business-level events which occur across multiple tiers.&amp;nbsp; The following steps provide a guide to using integrated logging to monitor business activity:</p>
  <h2>1. Identify significant business activities in your application</h2>
  <p>&amp;nbsp;In order to properly log business activity, you first must understand what the important activities that your application performs are, and what their logging needs are.&amp;nbsp; This information should come directly from the business requirements of an application (and should be added to the requirements documentation for the application if it's not present).&amp;nbsp; If you don't have a good breakdown of business activities for the application, the requirements modeling phase of a threat model is a good way to generate one.&amp;nbsp; The following are examples of significant business logic:</p>
  <ul>
    <li>
      <p>&amp;#123;&amp;#123; insert some examples here &amp;#125;&amp;#125;</p>
    </li>
  </ul>
  <h2>2. Determine what level of logging each activity requires</h2>
  <p>How much information you need to log about each activity depends on what you need to be able to say about an occurence of the activity after the fact.&amp;nbsp; There are three rough levels of logging, namely tracking, verification, and non-repudiation, each of which has an increasing requirement for what needs to be logged.</p>
  <h3>Logging for tracking</h3>
  <p>Logging for tracking purposes is appropriate when you only need to provide statistical data about transactions -- frequency, timing, etc.&amp;nbsp; As the statistics need to be accurate, per-event logging is still appropriate, particularly if flexibility is desired in the actual statistics to be gathered.</p>
  <h3>Logging for verification</h3>
  <p>Verification is slightly more in depth; all relevent basic information about the transaction should be recorded.&amp;nbsp; The goal of logging at this level is to provide a full record of transactions, sufficient to manually re-create the transaction.&amp;nbsp;&amp;nbsp;This is the default level to log at for most business logic.</p>
  <h3>Logging for nonrepudiation</h3>
  <p>Nonrepudiation is a significantly higher standard.&amp;nbsp; The goal here is to ensure that, if one of the parties to a transaction disputes the transaction, proof of the validity of the transaction can be produce.&amp;nbsp; Being able to provide this proof is an architecture-level issue, which will have implications for many security-relevant design issues, especially authentication, but the issue is fundamentally a logging one.&amp;nbsp; The hard part for nonrepudiation is ensuring that sufficient data exists within the system.&amp;nbsp; Log files designed to support nonrepudiation should include all data related to the transaction.&amp;nbsp; This data should ideally include cryptographic signatures, and should itself be signed to prevent tampering, and stored securely.</p>
  <h2>3. Ensure that all ways of&amp;nbsp;performing those activities&amp;nbsp;are logged with sufficient data</h2>
  <p>&amp;nbsp;Once you know all of the&amp;nbsp;business activies&amp;nbsp;which need to be&amp;nbsp;logged, and what levels they need to be logged at, you need to enumerate all of the ways of performing those activities.&amp;nbsp; For most applications, there will be a single entry point for any given activity, but more complicated applications may have more than one entry point.&amp;nbsp; Also, logging on multiple levels provides a form of defense in depth, in case higher levels of functionality are circumvented.&amp;nbsp; N-tier systems are a good example of this -- while the normal entry point may be through a web front-end, logging at the middleware and database layers is very important in detecting circumvention of the normal entry point.&amp;nbsp; When you do have multiple levels of logging, or even multiple non-hierarchical systems working together, it's vital that business-level logging provide a way of unifieing those disparate data sources into a single view.</p>
  <h2>4. Ensure that logs are monitored</h2>
  <p>&amp;nbsp;The next step is ensuring that logs are monitored and the information in them acted upon.&amp;nbsp; Logging won't do any good if the results never see the light of day.&amp;nbsp; Work with the operations team who will be managing the application to define a plan for monitoring and responding to log events.&amp;nbsp; Depending on the environment, you may need to define this from scratch, or you may be fitting into a pre-exisiting framework. </p>
  <p>If you're defining a monitoring framework from scratch, here are some things you need to consider: </p>
  <ul>
    <li>
      <p>When do the logs need to be monitored&amp;#8212;some applications will need 24x7 coverage, but many will be fine with 8x5. </p>
      <li>
        <p>How much time will log monitoring take&amp;#8212;if&amp;nbsp;your application is a&amp;nbsp;large ecommerce site, you may have a dedicated team for log monitoring, but a small web app may be safe enough with a sysadmin taking a look a couple times a day. </p>
        <li>
          <p>What are your response time needs&amp;#8212;if there's a serious problem with the site, it'll show up in the logs first; is your tolerance for problems defined in minutes, hours, or days? </p>
          <li>
            <p>What will your procedure for acting on potential issues be? </p>
            <li>
              <p>How will you control access to your logs and information derived from them; how sensitive is the information likely to be? </p>
              <li>
                <p>What response capabilities will the log monitoring team have?&amp;nbsp; Log monitoring on it's own does no good if the information can't be acted on&amp;#8212;suspcious events need to be investigated, accounts frozen, etc.</p>
              </li>
            </li>
          </li>
        </li>
      </li>
    </li>
  </ul>
  <h2>Pitfalls for logging</h2>
  <p>Logging information at the business level is harder than providing implementation level logs, like logs of specific function calls, web server traffic, or database queries.&amp;nbsp; Ensuring all of these disparate sources of information work together to provide a coherent view of business level events while still allowing the component implementation-level log entries that make up those events to be easily found is not an easy task.&amp;nbsp; Depending on the complexity of your application, this level of logging integration may not be necessary -- if it's possible to easily determine which business event a given database query is part of, for instance, you probably don't need to automate this sort of thing.&amp;nbsp; Larger and more complex applications, however, do require this sort of logging coordination.</p>
  <p>Logging too much information can end up being a problem of its own.&amp;nbsp; Once you have an idea of the volume of log events that you're seeing from your application, it may be worthwhile to implement some form of log throttling to reduce the flow of information to a rate at which you can act upon.&amp;nbsp; Good log throttling should only eliminate redundant information and should provide a way to surface the most important information first. </p>
  <p>Automatically taking action based on detection of anomolous conditions is a very dangerous thing to do, and is&amp;nbsp;best avoided.&amp;nbsp; While it may be reasonable to throttle the speed at which an event (say, a login attempt) may occur, preventing an action from occurring&amp;nbsp;may result in an easy-to-launch denial of service attack against your application. </p>
  <h1>Additional Resources</h1>
  <ul>
    <li>For more information see, "Chapter 4 - Design Guidelines for Secure Web Applications" at <a href="http://msdn2.microsoft.com/en-us/library/aa302420.aspx">http://msdn2.microsoft.com/en-us/library/aa302420.aspx</a></li>
  </ul>
  <hr />
  <p>Adapted from Microsoft patterns &amp; practices guidance.</p>]]></Data>
  </Content>
</TeamMentor_Article>